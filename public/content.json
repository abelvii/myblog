[{"title":"tkinter学习之路","date":"2018-08-13T08:32:55.000Z","path":"2018/08/13/something-about-tkinter/","text":"最近由于工作需要，自学了tkinter的一些东西，在使用过程中遇到了一些问题，现记录下来。 tkinter的使用示例代码123456import Tkinter as tkwindow = tk.TK()label = tk.Label(window, text='Hello world')label.pack()window.mainloop() 当然了，这段代码是最最简单的几行代码（而且很容易运行了看不到效果，因为gui窗口太小了找不到，我当时就没看到，还以为是运行出错了，又没看到错误提示。唉） tkinter实现动画效果tkinter运行的几个状态创建12window = tk.Tk()label = tk.Label(window, text='hello world') 顾名思义，这个阶段是创建各个组件以及进行各种绑定的阶段，在这个阶段不会生成gui的窗口。 在这个阶段需要做的有：gui组件的创建，事件监听的绑定，动画效果的创建 布局作为一个jser，还是更加喜欢用布局这个词 1label.pack() || lable.grid() || label.place() 这三个函数分别对应三种不同的布局方式，可以混合使用。 事件循环在创建了窗口之后会执行动画函数，执行了动画函数之后就会进入mainloop，这个也是我觉的tkinter最。。。难受的一个机制，江湖人称事件循环态。 在进入了事件循环态后，只有触发了事件才可以进行ui刷新。也就是说，这个阶段不会有类似前端中banner的动画 所以，如果想要有一个什么动画的话，只能通过两种方式，第一种是在mainloop之前通过使用label.after设置一个更新ui的timer；第二种就是通过触发事件的回调函数进行动画的编写，而且，递归无效。。。也就是说，通过回调函数写动画只能通过循环+sleep的方式。 emmm反正就是这么牛批，而且我觉得tkinter是我见过的最丑的gui界面= =。因为自己可以设置的属性相对不多，但是却很实用，而且相对来说学习起来比较快，容易上手，优点与缺点同样明显，所以也就忍了吧。 动画效果的实现123label.after(interval, func)mainloop() 一句话，使用递归，在func内部重新调用after函数，出了递归之后，窗口就会进入事件循环态，非常坑爹。 差不多就总结了这些，see u","tags":[{"name":"Python","slug":"Python","permalink":"http://118.126.95.65/tags/Python/"},{"name":"tkinter","slug":"tkinter","permalink":"http://118.126.95.65/tags/tkinter/"}]},{"title":"对于hexo new的web端构想","date":"2017-02-13T23:55:57.000Z","path":"2017/02/14/hexo&web/","text":"用了一段时间的hexo，感觉在pc端用着还是很方便的，但是有一些时候，想用手机在博客上记录一些自己的心情时却无能为力，所以突发奇想想要做一个hexo新建文章的web端，作为一名程序员，想要把一些繁琐的过程自动化实现，最首先的构想就是流程的控制，流程就分为几步： 1新建文章-&gt;修改博文类别等信息-&gt;编写markdown内容-&gt;更新hexo博客内容-&gt;上传到hexo博客仓库 以下所有内容都是以nodejs作为后端语言的构想。并且会在本月26号开学之后进行代码的实现 新建文章||新建文章&amp;&amp;修改博文类别信息用过hexo的都知道，新建文章的命令是hexo new “postname”，那么web端想要进行文章的新建就有两种方法，第一种就是运行hexo命令，第二种就是直接按照hexo new命令新建出来的文件的格式，使用fs进行新建文件，将一些必要信息输入进新建的文件中，个人偏向于使用第二种方法，因为第一种方法的流程控制比较麻烦，需要等hexo new命令，还需要进入新建出的文件进行信息的修改。第二种方法的优势就是可以在web端直接填写一些必要信息，将这些信息收到后直接填入md文件中，之后执行hexo g&amp;d命令。 所以暂时选用第二种方法。 编写markdown内容感觉这部分东西会比较简单，因为有一些很成熟的markdown编辑器，可以看见实时的效果。 这部分内容没有什么好思考的 更新hexo博客内容&amp;&amp;上传到仓库nodejs.process.exec运行hexo g和hexo d命令就可以了 安全性问题在web端新建文章，提交到后端时加上校验就可以了，在json文件中存入一个password，将前端的输入与password进行对比就可以了。不是特别麻烦。","tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://118.126.95.65/tags/nodejs/"},{"name":"hexo","slug":"hexo","permalink":"http://118.126.95.65/tags/hexo/"}]},{"title":"基于nodejs的web server II","date":"2017-01-26T12:57:46.000Z","path":"2017/01/26/nodejs-webserver-ii/","text":"在写上一篇博客的过程中，一边思考一边进行整体框架的构思，感觉思路很清晰，于是这几天过年的事情忙完了之后在今天下午进行了webserver的改进。 比如对routepool数据结构的改进，对流程的进一步完善。 路由流程的完善目前这个hexo的博客还是部署在github上，但是github的空间只有300m，如果以后一直写的话总会有一天空间不够，所以肯定是需要将博客部署到自己的服务器上面。这样的话就需要了解一下hexo的访问方式。 hexo的博客编写起来结构有一些复杂，需要解析markdown进行html的生成。但是这部分我暂时还没有研究到，只是看了一下文件结构，感觉博客的主体思想就是使用模板，将markdown中的内容解析到模板当中，至于具体是如何生成暂时还没有了解。但是整体的思想了解了之后就知道如何将hexo生成的文件放在自己的服务器上能够被用户访问到。 简单来说，想要实现上述效果只是需要在路由时进行静态资源的判断。也就是访问到路径所指向的文件夹时进行一次index.html是否存在的判断。 由于在流程中多次需要用到文件存在的判断以及静态资源的读取，返回。所以将这两个环节抽象为两个函数。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455const fileExist = function(pathname, existfn, unexistfn)&#123; fs.exists(pathname, function(exist)&#123; if(exist)&#123; existfn(); &#125; else&#123; unexistfn(); &#125; &#125;)&#125;;const staticFile = function(req,res,pathname,ext)&#123; let raw = fs.createReadStream(pathname); let acceptEncoding = req.headers['accept-encoding'] || \"\"; let matched = ext.match(headers.fileMatch); let expires = new Date(); expires.setTime(expires.getTime() + headers.maxAge * 1000); res.setHeader(\"Expires\", expires.toUTCString()); res.setHeader(\"Cache-Control\", \"max-age=\" + headers.maxAge); //判断304 fs.stat(pathname, function (err, stat) &#123; if (err) &#123; console.log(err); &#125; else &#123; lastModified = stat.mtime.toUTCString(); res.setHeader(\"Last-Modified\", lastModified); if (req.headers['if-modified-since'] &amp;&amp; lastModified == req.headers['if-modified-since']) &#123; res.writeHead(304, \"Not Modified\"); res.end(); &#125; //如果不是304 else &#123; if (matched &amp;&amp; acceptEncoding.match(/\\bgzip\\b/)) &#123; res.writeHead(200, \"Ok\", &#123; 'Content-Encoding': 'gzip', 'content-Type':header[matched[0]] &#125;); raw.pipe(zlib.createGzip()).pipe(res); &#125; else if (matched &amp;&amp; acceptEncoding.match(/\\bdeflate\\b/)) &#123; res.writeHead(200, \"Ok\", &#123; 'Content-Encoding': 'deflate', 'content-Type':header[matched[0]] &#125;); raw.pipe(zlib.createDeflate()).pipe(res); &#125; else &#123; res.writeHead(200, \"Ok\",&#123; 'content-Type':header[matched[0]] &#125;); raw.pipe(res); &#125; &#125; &#125; &#125;);&#125;; 路由流程的控制编写完静态资源以及判断文件是否存在方法之后就要进行流程的控制了，代码如下：1234567891011121314151617181920212223242526272829303132333435let pathname = url.parse(req.url);let pathN = pathname.pathname;let ext = path.extname(pathN);let headers = &#123; fileMatch: /^(gif|png|jpg|js|css|html)$/ig, maxAge: 60 * 60&#125;;ext = ext ? ext.slice(1) : 'unknown:';if (ext.match(headers.fileMatch)) &#123; this.staticFile(req,res,pathN,ext);&#125;else&#123; res.send = function(obj,str)&#123; if(str === 'json')&#123; res.writeHead(200,&#123;'content-Type':'application/json'&#125;); res.end(JSON.stringify(obj)); &#125; &#125;; if(req.method === 'GET')&#123; req.query = querystring.parse(pathN.query); that.router(req.method.toLowerCase(),pathN,req,res); &#125; else if(req.method === 'POST')&#123; req.setEncoding('utf-8'); let postData = \"\",params; req.addListener(\"data\", function (postDataChunk) &#123; postData += postDataChunk; &#125;); req.addListener(\"end\", function () &#123; params = querystring.parse(postData); req.query = params; that.router(req.method.toLowerCase(),pathN,req,res); &#125;); &#125;&#125; 这部分代码用于路由流程的控制，以及将get，post请求所发送的数据分别解析出来，get请求大部分情况下是在url中添加数据，而post请求则需要进行监听，因为是分段发送，至于为什么post请求是分段发送，我在百度中没有找到靠谱的答案，面试中也有被问到过，答得也不是特别满意，如果有知道的同学可以在下面留言，感谢。 routepool数据结构的设定routepool是路由的根本，所以，将routepool设为私有属性，app的get,post,use方法的作用相当于routepool的setter，而app.route则相当于routepool的getter。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152const fileExist = function(pathname, existfn, unexistfn)&#123; fs.exists(pathname, function(exist)&#123; if(exist)&#123; existfn(); &#125; else&#123; unexistfn(); &#125; &#125;)&#125;;let routerpool = &#123;&#125;;let pool = routerpool;app = &#123; post: function (str, callback) &#123; routerInit(str, pool); pool[str][\"method\"][\"post\"] = callback; return this; &#125;, get: function (str, callback) &#123; routerInit(str, pool); pool[str][\"method\"][\"get\"] = callback; return this; &#125;, use: function (str, callback) &#123; routerpool[str] = &#123;&#125;; routerpool[str][\"children\"] = &#123;&#125;; pool = routerpool[str][\"children\"]; callback(); pool = routerpool; return this; &#125;, router: function (method, str, req, res) &#123; let callback; let that = this; if ((callback = routerExist(str,method))) &#123; callback(req,res); &#125; else &#123; fileExist(\"public/view\"+str+\"/index.html\", function()&#123; staticFile(req,res,\"public/view\"+str+\"/index.html\",\"html\"); &#125;,function()&#123; if(routerpool[\"/404\"])&#123; routerpool[\"/404\"][\"method\"][\"get\"](req, res); &#125; else&#123; res.writeHead(404, \"Not found\"); res.end(); &#125; &#125;) &#125; &#125;,&#125; 目前use方法只能添加一层，且暂时没有添加通配符功能，通配符功能感觉有一些复杂，但是添加的话也应该是在router中进行添加路由匹配的另一种规则。 以上就是我对于web server的一些尝试，欢迎感兴趣的同学一起来讨论。感谢阅读 cheers！","tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://118.126.95.65/tags/nodejs/"}]},{"title":"基于nodejs的web server","date":"2017-01-23T01:35:45.000Z","path":"2017/01/23/node-route/","text":"有的同学可能很不理解，明明有那么多好用的nodejs的框架，你为什么要自己写一个，况且你写的肯定没有那些框架的用起来稳定，也没有那么舒服。 原因很简单，那次鹅厂的实习生面试，二面时面试官说用express做的后端没有什么技术含量。我觉得很有道理，想了很久什么样的框架用起来有技术含量。最后决定自己写一个。在写本篇博客过程中也重新梳理了一番思路，并对一些功能进行修改，在之后我会对框架进行修改。 这篇博客中代码不会有很多，还有很多的地方只是一些思想而已，目前并没有抽象为代码。不说闲话，上干货 router整体思路现在在网上有很多的简单运行一个http server的demo123456var http = require(\"http\");http.createServer(function(req,res)&#123; res.write(\"hello world\"); res.end();&#125;).listen(3000); 大概就是这样，这个很简单，但是如果想要自己来写一个server的话这些还远远不够。 首先要知道，nodejs是事件驱动模型，也就是每当有一个请求到了监听的端口时，都会运行一次httpserver回调函数的代码，所以我们可以根据这个进行路由的分发。 那么路由的分发也会分成几个部分，比如想要托管一部分的静态资源，并且进行缓存的控制，如访问某一个文件夹时自动返回index.html文件等简单功能，另外的就是通过自定义接口 比如1234app.get(\"url\",function(req,res)&#123; res.writeHead(200); res.end();&#125;); 这个就需要自己来编写对应的一些代码。还有一些功能就不一一列举了。 路由分发 路由分发最基本的操作就是url的解析，这个有原生的url模块支撑，具体用法为1url.parse(req,url); 分为两部分： 静态资源 可能有的同学会很不理解，静态资源的托管不是应该给服务器做的东西么，我从前知道的所有后端只需要配置跟文件目录就可以了。这个就是不同语言的不同之处了。node的httpserver是直接监听的端口，而静态资源究其根本也是一个get请求。所以这个也需要进行路由的分发，只不过是将静态资源的请求分发到同一个接口进行处理。 具体的操作是将解析后的url进行正则匹配判断是否为静态资源，如果是静态资源的话就使用req，res作为参数传到另外一个函数中进行操作。 在另外一个函数中进行资源的查找，分别判断是否存在（fs.exists），以及客户端资源是否与本地资源相同（fs.stat）也就是判断是否应该返回304. 自定义接口 这部分算是重头戏了，因为这才是我们做路由所需要的最多的地方。这部分的流程图如下 以前遇到过有个同学对这个流程有一些质疑，因为看起来这个流程有一些复杂，每次都要进行很多的判断，而且看起来和静态资源托管部分有重复。 这部分有一个优先级问题，我认为自定义接口优先级大于静态资源，所以这部分我的做法是这样的，也可以每次先进行静态资源的判断，即为 如果两种方法都想要用的话就可以通过进行一些参数的设置进行更改不同的流程，这个应该比较简单了。 接下来是自定义接口的定义，存储以及匹配问题，我个人在最开始的时候想到的方法是通过两个数组进行存储，当然这个方法很不稳定，经常会有出错的时候，大致就是接口的key,value在不同数组分别存储，然后通过array.indexOf进行判断key是否存在以及value的提取。 但是因为上述方法在实际测试中很不稳定，所以在当时重新梳理了一番思路，使用了另外一种方法，也就是key:value形式，使用object进行存储。这个方法还有一种好处就是可以很简单的实现app.use方法。 具体的数据形式就是12345678910111213141516171819202122routerpool&#123; \"url\":&#123; method:&#123; \"get\":function, \"post\":function &#125; &#125; \"url2\":&#123; method:&#123; \"get\":function, \"post\":function &#125; children:&#123; \"1\":&#123; method:&#123; \"get\":function, \"post\":function &#125; &#125; &#125; &#125;&#125; 上面的就是通过 12345678app.get(\"url\", function(req,res)&#123;&#125;);app.post(\"url\", function(req,res)&#123;&#125;);app.get(\"url2\", function(req,res)&#123;&#125;);app.post(\"url2\", function(req,res)&#123;&#125;);app.use(\"url2\", function(req,res)&#123; app.get(\"1\", function(req,res)&#123;&#125;); app.post(\"1\", function(req,res)&#123;&#125;);&#125;) 所构造的数据格式。实际访问的就是”url”,”url2/1”。这两个地址，通过不同的方法访问会有不同的代码。 判断是否存在接口就是用routerpool[url][method][req.method]判断是否存在，以及通过调用的方法不同进行fucntion的选择。 以上就是当前我对自己写httpserver的一些思想，心得，理解。感谢阅读 cheers！","tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://118.126.95.65/tags/nodejs/"}]},{"title":"我眼中的数据挖掘","date":"2017-01-22T02:55:52.000Z","path":"2017/01/22/data_mining_in_my_eyes/","text":"在16年的12月份我接触到的数据挖掘，也就是上个月，在很久很久以前就已经听说过这方面的东西，也一直都很想要学习一下数据挖掘这门技术，正巧上个月学校有一个数据挖掘的兴趣小组。故事就从这里开始了。。。 整体的流程虽然我现在连一个完整的项目都还没有做过，但是我就是想要写一下，用百度去搜数据挖掘的相关资料时，上面都是一些非常深奥的东西，对于像我这种新手不是十分友好，所以我就想要来写一些大概的流程，如果有大神发现有错误的话欢迎来指正。 总体的流程一共有几步 1取得数据-&gt;样本划分-&gt;特征提取-&gt;合并为数据集-&gt;训练模型-&gt;选取最优模型-&gt;end 取得数据这个感觉没什么说的，如果是比赛的话就直接下载就行了，如果是做项目就在数据库里面去提就行了。 样本划分在学习的时候就因为对这个概念的理解不正确以及对整体流程掌握的不正确而走了许多弯路。 数据集有三个，分别是训练集，验证集以及测试集。三个数据集的基本形式应该是相同的，只是在过程中的作用不同而名字也不同。顾名思义，训练集的作用就是训练模型，验证集的作用就是验证模型预测的准确度，测试集就是放在线上进行测试的数据集。 特征提取特征提取是根据划分之后的样本通过改变不同的特征提取的规则进行样本的特征的提取的工作。特征就是对样本的描述，作用就是将特征与样本数据合并进行模型的训练。 为什么要进行特征的提取？ 这个问题我有想过，通过了解人工神经网络有了一些认识。 个人理解来说，训练出来的模型更像是一个数学公式，也就是我们大家都很熟悉的n元一次方程。 简单了解神经网络通过阅读吴军博士的《数学之美》（第二版），非常浅显的了解了一些神经网络。 训练模型的过程个人觉得和神经网络应该有一些联系，神经网络如图： 神经网络分为几部分：输入端，神经元，输出端。 输入端就是key，神经元就是特征以及其所占权值，训练集中输出端就是标签，测试集中输出端就是结果了。 训练模型就是通过神经网络去分析各个特征所占的权值。最后进行一次函数变换就可以确定输出的结果了。 个人对于数据挖掘的理解暂时只有这些，感谢阅读。 cheers！","tags":[{"name":"数据挖掘","slug":"数据挖掘","permalink":"http://118.126.95.65/tags/数据挖掘/"}]},{"title":"hello world","date":"2017-01-21T01:39:26.000Z","path":"2017/01/21/first-blog/","text":"折腾了好久的博客，原本是想要自己去做所有的东西，但是因为懒所以只是做了一些就一直放在那里了。最近学了一些数据挖掘相关的东西，忍不住自己想要装逼的心情，正好这个假期没有出去实习，在家呆着就准备搞博客了，这个博客是hexo的，大概了解了一下。 今年我23不知不觉已经23岁了，距离大学毕业还有一段距离，现在就是心里想的最多，但是却最无能为力的时候。 每次独处都好像想了很多很多，但是又好像什么都没有想。 成长一直是一个沉重的话题。 算了。学习去了","tags":[{"name":"心情","slug":"心情","permalink":"http://118.126.95.65/tags/心情/"}]}]